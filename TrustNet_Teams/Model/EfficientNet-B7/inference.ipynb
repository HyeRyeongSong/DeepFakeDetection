{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from kernel_utils import *\n",
    "from training.zoo.classifiers import DeepFakeClassifier\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from albumentations.augmentations.functional import image_compression\n",
    "from facenet_pytorch.models.mtcnn import MTCNN\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "normalize_transform = Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_on_video(face_extractor, video_path, batch_size, input_size, models, strategy=np.mean, apply_compression=False):\n",
    "    \n",
    "    batch_size *= 4\n",
    "    try:\n",
    "        faces = face_extractor.process_video(video_path)\n",
    "        if len(faces) > 0:\n",
    "            x = np.zeros((batch_size, input_size, input_size, 3), dtype=np.uint8)\n",
    "            n = 0\n",
    "            for frame_data in faces:\n",
    "                for face in frame_data[\"faces\"]:\n",
    "                    resized_face = isotropically_resize_image(face, input_size)\n",
    "                    resized_face = put_to_center(resized_face, input_size)\n",
    "                    if apply_compression:\n",
    "                        resized_face = image_compression(resized_face, quality=90, image_type=\".jpg\")\n",
    "                    if n + 1 < batch_size:\n",
    "                        x[n] = resized_face\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        pass\n",
    "            if n > 0:\n",
    "                x = torch.tensor(x, device=\"cuda\").float()\n",
    "                # Preprocess the images.\n",
    "                x = x.permute((0, 3, 1, 2))\n",
    "                for i in range(len(x)):\n",
    "                    x[i] = normalize_transform(x[i] / 255.)\n",
    "                # Make a prediction, then take the average.\n",
    "                with torch.no_grad():\n",
    "                    preds = []\n",
    "                    for model in models:\n",
    "                        y_pred = model(x[:n].half())\n",
    "                        y_pred = torch.sigmoid(y_pred.squeeze())\n",
    "                        bpred = y_pred[:n].cpu().numpy()\n",
    "                        preds.append(strategy(bpred))\n",
    "                    return np.mean(preds)\n",
    "    except Exception as e:\n",
    "        print(\"Prediction error on video %s: %s\" % (video_path, str(e)))\n",
    "        \n",
    "    return 0.5\n",
    "\n",
    "def _predict_on_videos(face_extractor, videos, input_size, num_workers, test_dir, frames_per_video, models,\n",
    "                         strategy=np.mean,\n",
    "                         apply_compression=False):\n",
    "    def process_file(i):\n",
    "        filename = videos[i]\n",
    "        y_pred = _predict_on_video(face_extractor=face_extractor, video_path=os.path.join(test_dir, filename),\n",
    "                                  input_size=input_size,\n",
    "                                  batch_size=frames_per_video,\n",
    "                                  models=models, strategy=strategy, apply_compression=apply_compression)\n",
    "        return y_pred\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as pool:\n",
    "        with tqdm(total=len(videos)) as progress:\n",
    "            futures = []\n",
    "            for video in range(len(videos)):\n",
    "                future = pool.submit(process_file, video)\n",
    "                future.add_done_callback(lambda x : progress.update())\n",
    "                futures.append(future)\n",
    "            \n",
    "            results = []\n",
    "            for future in futures:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Version : 3.7.0\n",
    "\n",
    "test_list = [36,37,38,39,40,41,42,43,44]\n",
    "done_list = []\n",
    "\n",
    "MODEL=\"b7_888_DeepFakeClassifier_resnest269e_0_37\"\n",
    "ENCODER=\"resnest269e\"\n",
    "TESTDIR=\"/workspace/dataset/test/\"\n",
    "\n",
    "def predict(models, test_dir, encoder, output=\"submission.csv\", weights_dir=\"weights\"):\n",
    "    models = []\n",
    "    model_paths = [os.path.join(weights_dir, model) for model in models]\n",
    "    for path in model_paths:\n",
    "        model = DeepFakeClassifier(encoder=encoder).to(\"cuda\")\n",
    "        print(\"loading state dict {}\".format(path))\n",
    "        checkpoint = torch.load(path, map_location=\"cpu\")\n",
    "        state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "        model.load_state_dict({re.sub(\"^module.\", \"\", k): v for k, v in state_dict.items()}, strict=False)\n",
    "        model.eval()\n",
    "        del checkpoint\n",
    "        models.append(model.half())\n",
    "\n",
    "    frames_per_video = 32\n",
    "    video_reader = VideoReader()\n",
    "    video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "    face_extractor = FaceExtractor(video_read_fn)\n",
    "    input_size = 380\n",
    "    strategy = confident_strategy\n",
    "    stime = time.time()\n",
    "\n",
    "    test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n",
    "    print(\"Predicting {} videos\".format(len(test_videos)))\n",
    "    predictions = _predict_on_videos(face_extractor=face_extractor, input_size=input_size, models=models,\n",
    "                                       strategy=strategy, frames_per_video=frames_per_video, videos=test_videos,\n",
    "                                       num_workers=6, test_dir=test_dir)\n",
    "    submission_df = pd.DataFrame({\"filename\": test_videos, \"label\": predictions})\n",
    "    submission_df.to_csv(output, index=False)\n",
    "    print(\"Elapsed:\", time.time() - stime)\n",
    "    \n",
    "def inference_on_folder(number):\n",
    "    test_dir = f\"{TESTDIR}dfdc_train_part_{number}\" # Input path of test datas\n",
    "    output = f\"{number}.csv\"\n",
    "    print(f\"Start inference {test_dir}\")\n",
    "    predict(models=MODEL, test_dir=test_dir, encoder=ENCODER, output=output)\n",
    "\n",
    "def main():\n",
    "    for case in test_list:\n",
    "        if case in done_list: continue\n",
    "        inference_on_folder(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference /workspace/dataset/test/dfdc_train_part_37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2655 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2655 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  7%|â–‹         | 192/2655 [06:36<58:39,  1.43s/it]  "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
